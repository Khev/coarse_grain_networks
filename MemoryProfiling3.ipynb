{
 "metadata": {
  "name": "MemoryProfiling3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@profile\n",
      "def function():\n",
      "    g = nx.fast_gnp_random_graph(1000, 1./500)\n",
      "    g = nx.connected_component_subgraphs(g)[0]\n",
      "    A = nx.adjacency_matrix(g)\n",
      "    num_nodes = A.shape[0]\n",
      "    num_intervals, num_eigenvectors = 60,3\n",
      "    A = A / np.sum(A, 0)    #stochastic matrix -- don't need A anymore\n",
      "    eigenvalues,left_eigenvectors = eig(A, left = True, right = False)\n",
      "    groups = make_groups(eigenvalues, left_eigenvectors, num_intervals , num_eigenvectors)\n",
      "    \n",
      "    \"\"\"\n",
      "    R = make_R(groups, num_nodes)\n",
      "    K = make_K(groups, num_nodes, g)\n",
      "    W = np.dot(R, np.dot(A, K))\n",
      "    \"\"\"\n",
      "\n",
      "    A = s.csr_matrix(A)\n",
      "    R = make_sparse_R(groups, num_nodes)\n",
      "    K = make_sparse_K(groups, num_nodes,g)\n",
      "    W = np.dot(R, np.dot(A, K))\n",
      "\n",
      "\n",
      "\n",
      "import sys\n",
      "import random\n",
      "import logging\n",
      "import numpy as np\n",
      "from scipy.linalg import eig\n",
      "import networkx as nx\n",
      "import gc\n",
      "from scipy import sparse as s\n",
      "\n",
      "\n",
      "\n",
      "def coarse_grain_W(num_intervals, num_eigenvectors, g):\n",
      "    A = nx.adjacency_matrix(g)\n",
      "    num_nodes = A.shape[0]\n",
      "    A = A / np.sum(A, 0)    #stochastic matrix -- don't need A anymore\n",
      "    eigenvalues,left_eigenvectors = eig(A, left = True, right = False)\n",
      "    groups = make_groups(eigenvalues, left_eigenvectors, num_intervals , num_eigenvectors)\n",
      "    R = make_R(groups, num_nodes)\n",
      "    K = make_K(groups, num_nodes, g)\n",
      "    return np.dot(R, np.dot(A, K))\n",
      "\n",
      "\n",
      "def make_sparse_R(groups, num_nodes):\n",
      "    \"\"\" R_Ci := delta_C,i := 1 if node i is in group C, and \n",
      "        0 otherwise.\n",
      "        \n",
      "        See paper for fuller explanation.\n",
      "    \"\"\"\n",
      "    sparse_data = []\n",
      "    for group_number in xrange(len(groups)):\n",
      "        for node in groups[group_number]:\n",
      "            sparse_data.append([group_number, node, 1.0])\n",
      "    sparse_data = np.array(sparse_data)\n",
      "    return s.csr_matrix((sparse_data[:,2], (sparse_data[:,0], sparse_data[:,1])), shape=(len(groups), num_nodes))\n",
      "\n",
      "\n",
      "def make_sparse_K(groups, num_nodes, g):\n",
      "    sparse_data = []\n",
      "    degree_distribution = nx.degree(g).values()\n",
      "    for group_number in xrange(len(groups)):\n",
      "        group_degree = sum([degree_distribution[member] for member in groups[group_number]])\n",
      "        for node in groups[group_number]:\n",
      "            sparse_data.append([node, group_number, float(degree_distribution[node]) / group_degree ])\n",
      "    sparse_data = np.array(sparse_data)\n",
      "    return s.csr_matrix((sparse_data[:,2], (sparse_data[:,0], sparse_data[:,1])), shape=(num_nodes, len(groups)))\n",
      "\n",
      "\n",
      "def partition(vector, num_intervals):\n",
      "    \"\"\" Partitions the elements of a vector into\n",
      "        bins of length (max(vector) - min(vector))\n",
      "        / num_intervals. \n",
      "\n",
      "        Output: list of lists of vector components \n",
      "                belonging to the same partition. \n",
      "                E.g. [[v1,v2,v3], [v4,v5], ...], where\n",
      "                x1 < v1,v2,v3, < x2, i.e. they lie on the \n",
      "                first subinterval.\n",
      "    \"\"\"\n",
      "    \n",
      "    #check if vector is complex (if slightly -- im(v) < 10**-6 -- complex, set to 0)\n",
      "    if (vector.imag > 1).any():                                ##  !!change this bak to 10**-6!! ##\n",
      "        raise TypeError('Cannot tolerate complex eigenvalues')\n",
      "    else:\n",
      "        vector =  vector.astype(float)\n",
      "    \n",
      "    bins = np.linspace(min(vector), max(vector), num_intervals)\n",
      "    keys = range(1,len(bins)+1)\n",
      "    vals = [[] for i in range(len(keys))]\n",
      "    partitions = dict(zip(keys, vals))\n",
      "    which_bin = np.digitize(vector, bins)\n",
      "    for i in range(len(which_bin)):\n",
      "        partitions[which_bin[i]].append(i)\n",
      "    return partitions.values()\n",
      "\n",
      "\n",
      "def find_which_partition(element, partitioned_vector):\n",
      "    \"\"\" Returns the partition an element is in. E.g.\n",
      "        find_which_partition(v1, v) would return [v1,v2,v3]\n",
      "        if vector were partitioned as described in the doc\n",
      "        string for the partition function.\n",
      "    \"\"\"\n",
      "    for partition in partitioned_vector:\n",
      "        if element in partition:\n",
      "            return partition\n",
      "        \n",
      "        \n",
      "def find_max_eigenvalues_indices(l,num_eigenvectors):\n",
      "    \"\"\" Auxilary function -- to help find max eigenvectors.\n",
      "        eig function returning complex --> eigenvalues not sorted.\n",
      "        So, find indices of max eigenvalues, so that we can find\n",
      "        corresponding eigenvectors.\n",
      "        \n",
      "    \"\"\"\n",
      "    temp = 1\n",
      "    indices = []\n",
      "    while temp <= num_eigenvectors + 1:\n",
      "        indices.append(l.argmax() + temp - 1)\n",
      "        l = np.delete(l, l.argmax())\n",
      "        temp += 1\n",
      "    return indices[1:]             #we don't want the biggest eigenvalue (stationary dist.)\n",
      "\n",
      "\n",
      "def make_groups(eigenvalues, left_eigenvectors, num_intervals, num_eigenvectors):\n",
      "    \"\"\" Makes group as defined in coarse graining procedure. Vector\n",
      "        components v1,v2 are grouped together if x_n < v1,v2 < x_n+1, \n",
      "        for EACH of the first 'num_eigenvectors' eigenvectors specified.\n",
      "        The subinterval (x_n, x_n+1) are defined by [max(eigenvalue) - \n",
      "        min(eigenvalue)] / num_intervals.\n",
      "\n",
      "        Typically we take the first few non trivial eigenvectors to preserve\n",
      "        the long term behaviour of the RW; i.e. take <u1|, <u2|, <u3|.\n",
      "        \n",
      "        Roughly speaking, groups <u^alpha_i | and <u^alpha_j | together\n",
      "        if they are roughly equal to each other, for each alpha.\n",
      "        \n",
      "        Output: groups contain the node INDICES. E.g. groups = [[4,5,6], [7,6]]\n",
      "        mean the 4th, 5th etc nodes.\n",
      "\n",
      "    \"\"\"\n",
      "    \n",
      "    groups = []\n",
      "    indices = find_max_eigenvalues_indices(eigenvalues, num_eigenvectors)\n",
      "    partitioned_vectors = [partition(left_eigenvectors[:,i], num_intervals) for i in indices]\n",
      "\n",
      "    #Add non-empty groups\n",
      "    for p0_i in partitioned_vectors[0]:\n",
      "        for element_p0_i in p0_i:\n",
      "            sets = []\n",
      "            sets.append(set(p0_i))\n",
      "            for partitioned_vector in partitioned_vectors[1:]:                            #exclude first vector\n",
      "                sets.append(set(find_which_partition(element_p0_i, partitioned_vector)))\n",
      "            intersections = list(set.intersection(*sets))\n",
      "            if len(intersections) > 1:\n",
      "                if intersections not in groups:\n",
      "                    groups.append(intersections)\n",
      "                \n",
      "    #Add elements not in groups            \n",
      "    flattened_groups = set([item for sublist in groups for item in sublist])\n",
      "    all_vector_components = set(range(len(left_eigenvectors[:,0])))\n",
      "    for component in all_vector_components - flattened_groups:\n",
      "        groups.append([component])\n",
      "        \n",
      "    return groups\n",
      "\n",
      "\n",
      "        \n",
      "def make_K(groups, num_nodes, g):\n",
      "    \"\"\" K_iC := k_i / sum(k_j for j in group C) * delta_C,i\n",
      "        where k_i is the degree of node i, and delta_C_i =\n",
      "        1 if node i is in group C, and 0 otherwise.\n",
      "\n",
      "        See paper for fuller explantion\n",
      "    \"\"\"\n",
      "    \n",
      "    K = np.zeros((num_nodes, len(groups)))\n",
      "    degree_distribution = nx.degree(g).values()\n",
      "    for group_number in xrange(len(groups)):\n",
      "        group_degree = sum([degree_distribution[member] for member in groups[group_number]])\n",
      "        for node in groups[group_number]:\n",
      "            K[node, group_number] = float(degree_distribution[node]) / group_degree\n",
      "    return np.matrix(K)\n",
      "\n",
      "\n",
      "def make_R(groups, num_nodes):\n",
      "    \"\"\" R_Ci := delta_C,i := 1 if node i is in group C, and \n",
      "        0 otherwise.\n",
      "        \n",
      "        See paper for fuller explanation.\n",
      "    \"\"\"\n",
      "    R = np.zeros((len(groups), num_nodes))\n",
      "    for group_number in xrange(len(groups)):\n",
      "        for node in groups[group_number]:\n",
      "            R[group_number, node] = 1.0\n",
      "    return R      \n",
      "\n",
      "\n",
      "\n",
      "    \n",
      "if __name__ == '__main__':\n",
      "        function()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'profile' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-9-bb0396bdf73e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_gnp_random_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnected_component_subgraphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjacency_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'profile' is not defined"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}