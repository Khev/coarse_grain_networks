{
 "metadata": {
  "name": "OptimisedClumping"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "                                                   ## FUNCTIONS FOR INITIALISING GRAPHS ##\n",
      "import cPickle as pickle\n",
      "import networkx as nx\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import time\n",
      "import cProfile        \n",
      "import pycallgraph    #for profiling\n",
      "import pydot          #for profiling\n",
      "import math\n",
      "    \n",
      "\n",
      "class Timer():\n",
      "   def __enter__(self): self.start = time.time()\n",
      "   def __exit__(self, *args): print time.time() - self.start\n",
      "\n",
      "            \n",
      "#Makes a graph from [(x1,y1), ..], as stored in XWheatResults. Each node is labeled by a string of form 'x1 y1'. So, g['x1 y1'] return the node at (x1, y1).\n",
      "def makeGraph(data):\n",
      "    g = nx.Graph()\n",
      "    for i in xrange(len(data)):\n",
      "        g.add_node(str(data[i][0]) + ' ' + str(data[i][1]))\n",
      "    return g\n",
      "\n",
      "\n",
      "def dist(s1, s2):\n",
      "    \n",
      "    \"\"\"Return dist between to nodes, input: ('x1 y1', 'x2, y2'), i.e. as strings. \"\"\"\n",
      "        \n",
      "    temp1 = np.array([int(x) for x in s1.split()])\n",
      "    temp2 = np.array([int(x) for x in s2.split()])\n",
      "    \n",
      "    return math.hypot(temp1[0] - temp2[0], temp1[1] - temp2[1])\n",
      "   \n",
      "    \n",
      "#Returns array of positions, [[x1, y1], ...], of nodes in a graph g.\n",
      "def listPositions(g):\n",
      "    pos = [key for key in g.node]                  #list of positions as strings\n",
      "    for i in xrange(len(g.node)):\n",
      "        pos[i] = [int(x) for x in pos[i].split()]  #list of positions as [i,j]\n",
      "    return pos\n",
      "\n",
      "#plots nodes of graph as a scatter plot.\n",
      "def plotGraph(g):\n",
      "    temp = np.array(listPositions(g))\n",
      "    plt.scatter(temp[:,0], temp[:,1])\n",
      "\n",
      "\n",
      "#Connects node_i to node_j iff dist(node_i, node_j) <= R, for all node_i in the gprah.     \n",
      "def connect(g, R):            #R = radius of infection (in units of boxes = 30m)\n",
      "    pos = listPositions(g)\n",
      "    \n",
      "    #Sum (i,0,N), (j,0,N), i<j\n",
      "    for i in xrange(len(pos)):\n",
      "        for j in xrange(i+1, len(pos)):\n",
      "            if math.hypot(pos[i][0] - pos[j][0], pos[i][1] - pos[j][1]) <= R:\n",
      "                g.add_edge(str(pos[i][0]) + ' ' + str(pos[i][1]), str(pos[j][0]) + ' ' + str(pos[j][1]))   #convert [x1, y1] -> 'x1 y1'\n",
      "            \n",
      "                \n",
      "                \n",
      "#------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "                                                   ## FUNCTIONS FOR COARSE GRAINING ##\n",
      "#data of form [[x1, y1], [x2, y2], ...]                \n",
      "def probeLengthScale(data, r_min, r_max):\n",
      "    \"\"\"invesitgates how qualitative behaviour (the number of connected components: CC = Connected Component, #CC = number of CC) of graph changes as a function of \n",
      "       interaction radius. Computes the number of CC for each r, denoted CC(r), in the interval (r_min, r_max),\n",
      "       and if CC(r_i) != CC(r_min), stops and prints r_i. I developed this to test coarse graining. Best to use this on a subset of data (I took the first 500 from).\"\"\"\n",
      "    \n",
      "    g_coarse = makeGraph(data)\n",
      "    connect(g_coarse, r_min)\n",
      "    \n",
      "    for i in xrange(r_min, r_max):\n",
      "        g = makeGraph(data)\n",
      "        connect(g, i)\n",
      "        if nx.connected_components(g_coarse) != nx.connected_components(g):\n",
      "            print 'Different # of connected components at r =  ' + str(i)\n",
      "            break\n",
      "            \n",
      "            \n",
      "#Input: nx.Graph(). Output: list of nodes (one from each CC)\n",
      "def mostConnectedNodes(g):\n",
      "    \"Finds which node has highest degree in each CC\"\n",
      "    \n",
      "    connected_components = nx.connected_components(g)\n",
      "    return [max(g.degree(i).iteritems(), key = lambda x:x[1])[0] for i in connected_components ]\n",
      "\n",
      "\n",
      "#Input: n = node, connected_components = list of connected components, (CC)\n",
      "def getNeighbors(n, connected_components):\n",
      "    return [i for i in connected_components if n in i]\n",
      "\n",
      "#Input: most_connected = list of nodes with highest degree, one from each CC\n",
      "def findBiggestNeighbor(n, connected_components, most_connected):\n",
      "    \"\"\"Biggest = node with highest degree  \"\"\"\n",
      "    return [most_connected[i] for i in xrange(len(connected_components)) if n in connected_components[i]]\n",
      "\n",
      "#Input: rips reduce CC, original CC                                \n",
      "def findBiggestExternalNode(n, smallCC, bigCC, most_connected_gg):\n",
      "    nearNeighbors = getNeighbors(n, smallCC)  \n",
      "    farNeighbors = getNeighbors(n, bigCC)\n",
      "    \n",
      "    if nearNeighbors != farNeighbors:\n",
      "        uncommonNeighbors = list(set(farNeighbors[0]) - set(nearNeighbors[0]))  #taking [0] deals with overbracketing issues\n",
      "        \n",
      "        temp = []\n",
      "        for i in uncommonNeighbors: \n",
      "            temp.append(findBiggestNeighbor(i, smallCC, most_connected_gg)[0])\n",
      "            temp = list(set(temp))\n",
      "            \n",
      "        return temp\n",
      "    \n",
      "    else:\n",
      "        return 0   #if no neighbours, return 0. Is this bad practice?\n",
      "    \n",
      "def connectCoarseGraph(most_connected_gg, radius_of_infection, g_coarse):\n",
      "    \"\"\"Connectes nodes in g_coarse if they were connected in g_original \"\"\"\n",
      "    \n",
      "    for i in xrange(len(most_connected_gg)):\n",
      "        for j in xrange(i+1, len(most_connected_gg)):\n",
      "                if dist(most_connected_gg[i], most_connected_gg[j]) <= radius_of_infection:  \n",
      "                #if not most_connected_gg[i] in g[most_connected_gg[j]]:                     #check if node i was unconnected to node j in graph g\n",
      "                    g_coarse.add_edge(most_connected_gg[i], most_connected_gg[j])\n",
      "    \n",
      "    \n",
      "def connectNeighborsNeigbors(most_connected_gg, connected_components_gg, connected_components_g, g_coarse, g):\n",
      "    \"\"\"Connects nodes in g_coarse, if they had neighbors who were connected, and weren't connected themselves --> if the sub-clusters were connected. \"\"\"\n",
      "    \n",
      "    for i in xrange(len(connected_components_gg)):\n",
      "        \n",
      "        big_node = most_connected_gg[i]                                                #this is the node with highest degree, in each CC\n",
      "        small_nodes = connected_components_gg[i][0:len(connected_components_gg[i])]    #this is a list of big_nodes neighbors. Strange notation, l = list[0:end], \n",
      "        small_nodes.remove(big_node)                                                   #since python treats lists by reference                                                   \n",
      "    \n",
      "        for j in small_nodes:\n",
      "            # If any small node has a neighbour that the big node isn't connected to (unconnected Neighbor), connect the big node to this neighbour.\n",
      "            unconnectedNeighbor = findBiggestExternalNode(j, connected_components_gg, connected_components_g, most_connected_gg)\n",
      "            \n",
      "            for k in unconnectedNeighbor:\n",
      "                if not k == 0:                                            #0 means there is no neighbor, so if there IS a neighbour.\n",
      "                    if not big_node in g_coarse[k]:                              # in big_node wasn't originally (in original graph) connected to\n",
      "                #if not isConnected(unconnectedNeighbor[0], big_node, g):                neighbours neighbours, connect them.\n",
      "                        g_coarse.add_edge(big_node, k)\n",
      "                    \n",
      "                    \n",
      "def convexHull(points):\n",
      "    \"\"\"Computes the convex hull of a set of 2D points.\n",
      " \n",
      "    Input: an iterable sequence of (x, y) pairs representing the points.\n",
      "    Output: a list of vertices of the convex hull in counter-clockwise order,\n",
      "      starting from the vertex with the lexicographically smallest coordinates.\n",
      "    Implements Andrew's monotone chain algorithm. O(n log n) complexity.\n",
      "    \"\"\"\n",
      " \n",
      "    # Sort the points lexicographically (tuples are compared lexicographically).\n",
      "    # Remove duplicates to detect the case we have just one unique point.\n",
      "    points = sorted(set(points))\n",
      " \n",
      "    # Boring case: no points or a single point, possibly repeated multiple times.\n",
      "    if len(points) <= 1:\n",
      "        return points\n",
      " \n",
      "    # 2D cross product of OA and OB vectors, i.e. z-component of their 3D cross product.\n",
      "    # Returns a positive value, if OAB makes a counter-clockwise turn,\n",
      "    # negative for clockwise turn, and zero if the points are collinear.\n",
      "    def cross(o, a, b):\n",
      "        return (a[0] - o[0]) * (b[1] - o[1]) - (a[1] - o[1]) * (b[0] - o[0])\n",
      " \n",
      "    # Build lower hull \n",
      "    lower = []\n",
      "    for p in points:\n",
      "        while len(lower) >= 2 and cross(lower[-2], lower[-1], p) <= 0:\n",
      "            lower.pop()\n",
      "        lower.append(p)\n",
      " \n",
      "    # Build upper hull\n",
      "    upper = []\n",
      "    for p in reversed(points):\n",
      "        while len(upper) >= 2 and cross(upper[-2], upper[-1], p) <= 0:\n",
      "            upper.pop()\n",
      "        upper.append(p)\n",
      " \n",
      "    # Concatenation of the lower and upper hulls gives the convex hull.\n",
      "    # Last point of each list is omitted because it is repeated at the beginning of the other list. \n",
      "    return lower[:-1] + upper[:-1]\n",
      "\n",
      "\n",
      "def areClustersConnected(boundary1, boundary2, radius_of_infection):\n",
      "    \"\"\" Checks if Cluster (connected_component) 1, 2, having boundary 1, 2, are within radius of infection.\n",
      "        boundaryI is a list of lists: { boundary_of_connected_component_i  }      \"\"\"\n",
      "    \n",
      "    temp = False\n",
      "    \n",
      "    for i in xrange(len(boundary1)):\n",
      "        for j in xrange(len(boundary2)):\n",
      "            if math.hypot(boundary1[i][0] - boundary2[j][0], boundary1[i][1] - boundary2[j][1]) <= radius_of_infection:\n",
      "                temp = True\n",
      "                break\n",
      "    return temp\n",
      "            \n",
      "def stringsToTuples(connected_components):\n",
      "    \"\"\" Change data structure \"\"\"\n",
      "    \n",
      "    temp = []\n",
      "    for l in connected_components:    \n",
      "      temp.append([tuple([int(x) for x in i.split()]) for i in l])\n",
      "    \n",
      "    return temp\n",
      "            \n",
      "def findBoundaries(connected_components):\n",
      "    positions = stringsToTuples(connected_components)\n",
      "    return [convexHull(i) for i in positions]\n",
      "\n",
      "\n",
      "def connectClusters(connected_components_gg, g_coarse, most_connected_gg, radius_of_infection):\n",
      "    \"\"\"Connected Clusters if they are within the radius of infection \"\"\"\n",
      "    \n",
      "    boundaries = findBoundaries(connected_components_gg)\n",
      "    \n",
      "    for i in xrange(len(boundaries)):\n",
      "        for j in xrange(i+1, len(boundaries)):\n",
      "            if areClustersConnected(boundaries[i], boundaries[j], radius_of_infection):\n",
      "                g_coarse.add_edge(most_connected_gg[i], most_connected_gg[j])\n",
      "                    \n",
      "                    \n",
      "#------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "                                                   ## MAIN ##\n",
      "    \n",
      "def main(data, radius_of_infection, rips_radius):\n",
      "    \n",
      "    #Make and connect graphs\n",
      "    print 'Making Graphs'\n",
      "    #Don't need the initial graph anymore\n",
      "    #g = makeGraph(data)                                   #Original graph\n",
      "    #connect(g, radius_of_infection)\n",
      "    \n",
      "    gg = makeGraph(data)                                  #Rips Reduce graph (coarse graining length)\n",
      "    connect(gg, rips_radius)\n",
      "    \n",
      "    print \"Finding CC's\"\n",
      "    connected_components_gg = nx.connected_components(gg) #Find the CC's\n",
      "    most_connected_gg = mostConnectedNodes(gg)            #Find the list of 'biggest' nodes (one for each CC)\n",
      "    \n",
      "    #connected_components_g = nx.connected_components(g)\n",
      "    \n",
      "    #Coarse grained Graph\n",
      "    g_coarse = nx.Graph()\n",
      "    g_coarse.add_nodes_from(most_connected_gg)\n",
      "    \n",
      "    \"\"\" Old Way \n",
      "    print \"Coarse Graining\"\n",
      "    #Connect coarse grained graph\n",
      "    connectCoarseGraph(most_connected_gg, radius_of_infection, g_coarse)\n",
      "    connectNeighborsNeigbors(most_connected_gg, connected_components_gg, connected_components_g, g_coarse, g) \"\"\"\n",
      "    \n",
      "    #New way - compute boundary\n",
      "    connectClusters(connected_components_gg, g_coarse, most_connected_gg, radius_of_infection)\n",
      "    \n",
      "    return g_coarse                              # return the coarse grained graph.                        \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "#All cells are commented out, so that .py can be imported without evaluation\n",
      "\n",
      "data = pickle.load(open('SpringWheatPositions'))\n",
      "results = main(data, 500, 5)\n",
      "pickle.dump(results, open( \"CoarseGrainedSpringWheat\", \"wb\" ) )\n",
      "\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "'\\n#All cells are commented out, so that .py can be imported without evaluation\\n\\ndata = pickle.load(open(\\'SpringWheatPositions\\'))\\nresults = main(data, 500, 5)\\npickle.dump(results, open( \"CoarseGrainedSpringWheat\", \"wb\" ) )\\n\\n'"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "data1 = pickle.load(open('WinterWheatResults'))\n",
      "results = main(data1, 500, 5)\n",
      "pickle.dump(results, open( \"CoarseGrainedWinterWheat\", \"wb\" ) )\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Making Graphs\n",
        "Finding CC's"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "#Work with smaller data set first\n",
      "data = pickle.load(open('SpringWheatResults'))\n",
      "sdata = data[:5000]   #2000 takes ~ 20s\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "Below is for timing / profiling\n",
      "\n",
      "with Timer():\n",
      "    results = main(sdata, 350, 1)\n",
      "    \n",
      "pycallgraph.start_trace()\n",
      "cProfile.run('main(sdata, 350, 1)')\n",
      "pycallgraph.make_dot_graph('BottleNeck.png')\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Making Graphs\n",
        "Finding CC's"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "7.2799808979"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 81
    }
   ],
   "metadata": {}
  }
 ]
}