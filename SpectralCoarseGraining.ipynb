{
 "metadata": {
  "name": "SpectralCoarseGraining"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#---------------------------------------------------- Spectral Coarse Graining ------------------------------------------------------------------\n",
      "\n",
      "\"\"\" Based on \"Spectral Coarse Graining of Complex Networks\" by\n",
      "    David Gfeller and Paolo De Los Rios\n",
      "    \ufffcLaboratoire de Biophysique Statistique, SB/ITP, Ecole Polytechnique Fe \u0301de \u0301rale de Lausanne (EPFL), CH-1015, Lausanne, Switzerland\n",
      "    (Received 26 February 2007; published 19 July 2007)\n",
      "\n",
      "    NOTE: sometimes eigenvalues are complex, and I just take the real part. I haven't justified this.\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "import numpy as np\n",
      "from scipy.linalg import eig\n",
      "import networkx as nx\n",
      "from sets import Set\n",
      "from scipy import sparse as s\n",
      "import matplotlib.pyplot as plt\n",
      "from scipy.sparse.linalg import eigs\n",
      "\n",
      "\"\"\"\n",
      "if __name__ == '__main__':        \n",
      "    #g = nx.read_dot('shortened_winter_wheat_56mresolution_upstate_ny_20box_radius_inf.dot')\n",
      "    g = nx.read_dot('ExampleGraph1.dot')\n",
      "    cc = nx.connected_component_subgraphs(g)\n",
      "    num_intervals, num_eigenvectors = 60, 3\n",
      "    for sub_graph in cc:\n",
      "        if len(sub_graph.nodes()) > 2:\n",
      "            A = nx.adjacency_matrix(sub_graph)\n",
      "            A = A / np.sum(A, 0)\n",
      "            eigenvalues = eig(A, right = False)\n",
      "            coarse_W = coarse_grain_W(num_intervals, num_eigenvectors, g)\n",
      "            coarse_eigenvalues = eig(coarse_W, right = False)\n",
      "            g = coarsen_graph(g, groups)\n",
      "            fout = open(str(num_eigenvectors) + 'eigenvalues_preserved_connected_component ' + str(cc.index(sub_graph)) + '.npz', 'w+')\n",
      "            np.savez(fout, g, eigenvalues, coarse_eigenvalues)   #add in graphs?\n",
      "            fout.close\n",
      "\"\"\"\n",
      "\n",
      "\n",
      "\n",
      "def coarse_grain_W(num_intervals, num_eigenvectors, g, sparse = True):\n",
      "    \"\"\" Produces W_tilde := R*W*K, where W is the stochastic\n",
      "        matrix of the original graph, and R,K, are intermediary\n",
      "        matrices defined in the paper.\n",
      "\n",
      "        Has an optional arguments to use non-sparse matrices, which are\n",
      "        (minorly) faster for small graphs.\n",
      "    \"\"\"\n",
      "\n",
      "    \n",
      "    A = nx.adjacency_matrix(g)\n",
      "    num_nodes = A.shape[0]\n",
      "    A = A / np.sum(A, 0)    #stochastic matrix -- don't need A anymore\n",
      "    A = np.nan_to_num(A)\n",
      "    eigenvalues,left_eigenvectors = eig(A, left = True, right = False)\n",
      "    \n",
      "    if sparse == True:\n",
      "        A = s.csr_matrix(A)\n",
      "        groups = make_groups(eigenvalues, left_eigenvectors, num_intervals , num_eigenvectors)\n",
      "        R = make_sparse_R(groups, num_nodes)\n",
      "        K = make_sparse_K(groups, num_nodes, g)\n",
      "        return np.dot(R, np.dot(A, K))\n",
      "    \n",
      "    else:\n",
      "        groups = make_groups(eigenvalues, left_eigenvectors, num_intervals , num_eigenvectors)\n",
      "        R = make_R(groups, num_nodes)\n",
      "        K = make_K(groups, num_nodes, g)\n",
      "        return np.dot(R, np.dot(A, K))\n",
      "\n",
      "\n",
      "def partition(vector, num_intervals):\n",
      "    \"\"\" Partitions the elements of a vector into\n",
      "        bins of length (max(vector) - min(vector))\n",
      "        / num_intervals. \n",
      "\n",
      "        Output: list of lists of vector components \n",
      "                belonging to the same partition. \n",
      "                E.g. [[v1,v2,v3], [v4,v5], ...], where\n",
      "                x1 < v1,v2,v3, < x2, i.e. they lie on the \n",
      "                first subinterval.\n",
      "    \"\"\"\n",
      "    \n",
      "    #check if vector is complex (if slightly -- im(v) < 10**-6 -- complex, set to 0)\n",
      "    if (vector.imag > 1).any():                                ##  !!change this bak to 10**-6!! ##\n",
      "        raise TypeError('Cannot tolerate complex eigenvalues')\n",
      "    else:\n",
      "        vector =  vector.astype(float)\n",
      "    \n",
      "    bins = np.linspace(min(vector), max(vector), num_intervals)\n",
      "    keys = range(1,len(bins)+1)\n",
      "    vals = [[] for i in range(len(keys))]\n",
      "    partitions = dict(zip(keys, vals))\n",
      "    which_bin = np.digitize(vector, bins)\n",
      "    for i in range(len(which_bin)):\n",
      "        partitions[which_bin[i]].append(i)\n",
      "    return partitions.values()\n",
      "\n",
      "\n",
      "def find_which_partition(element, partitioned_vector):\n",
      "    \"\"\" Returns the partition an element is in. E.g.\n",
      "        find_which_partition(v1, v) would return [v1,v2,v3]\n",
      "        if vector were partitioned as described in the doc\n",
      "        string for the partition function.\n",
      "    \"\"\"\n",
      "    for partition in partitioned_vector:\n",
      "        if element in partition:\n",
      "            return partition\n",
      "        \n",
      "        \n",
      "def find_max_eigenvalues_indices(l,num_eigenvectors):\n",
      "    \"\"\" Auxilary function -- to help find max eigenvectors.\n",
      "        eig function returning complex --> eigenvalues not sorted.\n",
      "        So, find indices of max eigenvalues, so that we can find\n",
      "        corresponding eigenvectors.\n",
      "        \n",
      "    \"\"\"\n",
      "    temp = 1\n",
      "    indices = []\n",
      "    while temp <= num_eigenvectors + 1:\n",
      "        indices.append(l.argmax() + temp - 1)\n",
      "        l = np.delete(l, l.argmax())\n",
      "        temp += 1\n",
      "    return indices[1:]             #we don't want the biggest eigenvalue (stationary dist.)\n",
      "\n",
      "\n",
      "\n",
      "def make_groups(eigenvalues, left_eigenvectors, num_intervals, num_eigenvectors):\n",
      "    \"\"\" Makes group as defined in coarse graining procedure. Vector\n",
      "        components v1,v2 are grouped together if x_n < v1,v2 < x_n+1, \n",
      "        for EACH of the first 'num_eigenvectors' eigenvectors specified.\n",
      "        The subinterval (x_n, x_n+1) are defined by [max(eigenvalue) - \n",
      "        min(eigenvalue)] / num_intervals.\n",
      "\n",
      "        Typically we take the first few non trivial eigenvectors to preserve\n",
      "        the long term behaviour of the RW; i.e. take <u1|, <u2|, <u3|.\n",
      "        \n",
      "        Roughly speaking, groups <u^alpha_i | and <u^alpha_j | together\n",
      "        if they are roughly equal to each other, for each alpha.\n",
      "        \n",
      "        Output: groups contain the node INDICES. E.g. groups = [[4,5,6], [7,6]]\n",
      "        mean the 4th, 5th etc nodes.\n",
      "\n",
      "    \"\"\"\n",
      "    \n",
      "    groups = []\n",
      "    indices = find_max_eigenvalues_indices(eigenvalues, num_eigenvectors)\n",
      "    partitioned_vectors = [partition(left_eigenvectors[:,i], num_intervals) for i in indices]\n",
      "\n",
      "    #Add non-empty groups\n",
      "    for p0_i in partitioned_vectors[0]:\n",
      "        for element_p0_i in p0_i:\n",
      "            sets = []\n",
      "            sets.append(set(p0_i))\n",
      "            for partitioned_vector in partitioned_vectors[1:]:                            #exclude first vector\n",
      "                sets.append(set(find_which_partition(element_p0_i, partitioned_vector)))\n",
      "            intersections = list(set.intersection(*sets))\n",
      "            if len(intersections) > 1:\n",
      "                if intersections not in groups:\n",
      "                    groups.append(intersections)\n",
      "                \n",
      "    #Add elements not in groups            \n",
      "    flattened_groups = set([item for sublist in groups for item in sublist])\n",
      "    all_vector_components = set(range(len(left_eigenvectors[:,0])))\n",
      "    for component in all_vector_components - flattened_groups:\n",
      "        groups.append([component])\n",
      "        \n",
      "    return groups\n",
      "\n",
      "\n",
      "\n",
      "def make_sparse_K(groups, num_nodes, g):\n",
      "    sparse_data = []\n",
      "    degree_distribution = nx.degree(g).values()\n",
      "    for group_number in xrange(len(groups)):\n",
      "        group_degree = sum([degree_distribution[member] for member in groups[group_number]])\n",
      "        for node in groups[group_number]:\n",
      "            try:\n",
      "                sparse_data.append([node, group_number, float(degree_distribution[node]) / group_degree ])\n",
      "            except ZeroDivisionError:                           # this sets 0/0 = 1, that is, if the node is completely isoltated, degree(node) / degree(group) = 0.0\n",
      "                sparse_data.append([node, group_number, 1.0])\n",
      "    sparse_data = np.array(sparse_data)\n",
      "    return s.csr_matrix((sparse_data[:,2], (sparse_data[:,0], sparse_data[:,1])), shape=(num_nodes, len(groups)))\n",
      "\n",
      "\n",
      "def make_sparse_R(groups, num_nodes):\n",
      "    \"\"\" R_Ci := delta_C,i := 1 if node i is in group C, and \n",
      "        0 otherwise.\n",
      "        \n",
      "        See paper for fuller explanation.\n",
      "    \"\"\"\n",
      "    sparse_data = []\n",
      "    for group_number in xrange(len(groups)):\n",
      "        for node in groups[group_number]:\n",
      "            sparse_data.append([group_number, node, 1.0])\n",
      "    sparse_data = np.array(sparse_data)\n",
      "    return s.csr_matrix((sparse_data[:,2], (sparse_data[:,0], sparse_data[:,1])), shape=(len(groups), num_nodes))\n",
      "        \n",
      "\n",
      "\n",
      "def make_K(groups, num_nodes, g):\n",
      "    \"\"\" K_iC := k_i / sum(k_j for j in group C) * delta_C,i\n",
      "        where k_i is the degree of node i, and delta_C_i =\n",
      "        1 if node i is in group C, and 0 otherwise.\n",
      "\n",
      "        See paper for fuller explantion\n",
      "    \"\"\"\n",
      "    \n",
      "    K = np.zeros((num_nodes, len(groups)))\n",
      "    degree_distribution = nx.degree(g).values()\n",
      "    for group_number in xrange(len(groups)):\n",
      "        group_degree = sum([degree_distribution[member] for member in groups[group_number]])\n",
      "        for node in groups[group_number]:\n",
      "            try:\n",
      "                K[node, group_number] = float(degree_distribution[node]) / group_degree\n",
      "            except ZeroDivisionError:\n",
      "                K[node, group_numer] = 1.0\n",
      "    return np.matrix(K)\n",
      "\n",
      "\n",
      "def make_R(groups, num_nodes):\n",
      "    \"\"\" R_Ci := delta_C,i := 1 if node i is in group C, and \n",
      "        0 otherwise.\n",
      "        \n",
      "        See paper for fuller explanation.\n",
      "    \"\"\"\n",
      "    R = np.zeros((len(groups), num_nodes))\n",
      "    for group_number in xrange(len(groups)):\n",
      "        for node in groups[group_number]:\n",
      "            R[group_number, node] = 1.0\n",
      "    return R\n",
      "\n",
      "\n",
      "\n",
      "def inspect_coarse_graining(num_intervals, num_eigenvectors, g):\n",
      "    \"\"\" Prints some quantitative comparisons between the \n",
      "        coarse grained and non - coarse grained graphs.\n",
      "    \"\"\"\n",
      "    \n",
      "    A = nx.adjacency_matrix(g)\n",
      "    W_tilde = coarse_grain_W(num_intervals, num_eigenvectors,g)\n",
      "    A = A / np.sum(A, 0)\n",
      "    A = np.nan_to_num(A)\n",
      "    print 'Dimension [After, Before]: ' + str([W_tilde.shape[0], A.shape[0]])\n",
      "    l = eig(A, right = False)\n",
      "    l_tilde = eigs(W_tilde, k = W_tilde.shape[0] - 2, which = 'LR', return_eigenvectors=False)\n",
      "    l_tilde.sort()\n",
      "    l_tilde = l_tilde[::-1]\n",
      "    l.sort()\n",
      "    l = l[::-1]\n",
      "    print 'Eigenvalues Before: ' + str(l[:num_eigenvectors+1])\n",
      "    print 'Eigenvalues After: ' + str(l_tilde[:num_eigenvectors+1])\n",
      "    print '% Difference in eigenvalues: ' + str(100*abs(l_tilde[:num_eigenvectors+1] - l[:num_eigenvectors+1]) / abs(l[:num_eigenvectors+1]))\n",
      "    plt.figure()\n",
      "    plt.xlabel('Alpha')\n",
      "\n",
      "    plt.ylabel('Eigenvalue')\n",
      "    plt.title('For ' + str(num_intervals) + ' intervals')\n",
      "    plt.plot(l_tilde[:num_eigenvectors+8], 'ko')\n",
      "    plt.plot(l[:num_eigenvectors+8], 'ro')\n",
      "    plt.legend()\n",
      "\n",
      "    \n",
      "    \n",
      "    \n",
      "def coarsen_graph(g, num_intervals, num_eigenvectors, groups = 1):\n",
      "    \"\"\" Merges nodes that have been grouped together by the condition <u_i| ~= <u_j|\n",
      "        into 'supernodes', such that the neighbours of the supernode is the sum of the \n",
      "        neighbours of the individual nodes.\n",
      "\n",
      "        Input: g = nx.graph().\n",
      "               Optional groups, as returned from the make_groups() function. \n",
      "    \"\"\"\n",
      "\n",
      "    if groups == 1:                 #if groups haven't been specified, make them.\n",
      "        A = nx.adjacency_matrix(g)\n",
      "        num_nodes = A.shape[0]\n",
      "        A = A / np.sum(A, 0)    #stochastic matrix -- don't need A anymore\n",
      "        A = np.nan_to_num(A)\n",
      "        eigenvalues,left_eigenvectors = eig(A, left = True, right = False)\n",
      "        groups = make_groups(eigenvalues, left_eigenvectors, num_intervals , num_eigenvectors)\n",
      "        \n",
      "    nodes_to_be_merged = [[g.nodes()[i] for i in sublist] for sublist in groups if len(sublist) > 1]   #swapping node 'indices' to node 'names'\n",
      "    for group in nodes_to_be_merged:                                                                   # i.e. 1st node --> name of first node as in graph\n",
      "        neighbours = set([])                                                                           # and only take len(groups) > 1\n",
      "        for node in group:\n",
      "            for neighbour in nx.neighbors(g, node): \n",
      "                neighbours.add(neighbour)\n",
      "        neighbours = neighbours - set(group)\n",
      "        edge_list = [(tuple(group), neighbour) for neighbour in neighbours]\n",
      "        g.remove_nodes_from(group)\n",
      "        g.add_node(tuple(group))\n",
      "        g.add_edges_from(edge_list)\n",
      "    return g"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 327
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}