{
 "metadata": {
  "name": "MemoryProfiling"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Profiling Spectral Coarse Graining\n",
      "@profile\n",
      "def function():\n",
      "    g_trial = nx.fast_gnp_random_graph(1000, 0.1)\n",
      "    A = nx.adjacency_matrix(g_trial)\n",
      "    W = A / np.sum(A, 0)    #stochastic matrix\n",
      "    left_eigenvectors = eig(W, left = True, right = False)[1]\n",
      "    num_intervals = 20\n",
      "    num_eigenvectors = 3\n",
      "    groups = make_groups(left_eigenvectors, num_intervals , num_eigenvectors)\n",
      "    R = make_R(groups, A)\n",
      "    K = make_K(groups, A)\n",
      "    return np.dot(R, np.dot(W, K))\n",
      "    \n",
      "    \n",
      "def partition(vector, num_intervals):\n",
      "    \"\"\" Partitions the elements of a vector into\n",
      "        bins of length (max(vector) - min(vector))\n",
      "        / num_intervals. \n",
      "\n",
      "        Output: list of lists of vector components \n",
      "                belonging to the same partition. \n",
      "                E.g. [[v1,v2,v3], [v4,v5], ...], where\n",
      "                x1 < v1,v2,v3, < x2, i.e. they lie on the \n",
      "                first subinterval.\n",
      "    \"\"\"\n",
      "    \n",
      "    bins = np.linspace(min(vector), max(vector), num_intervals)\n",
      "    keys = range(1,len(bins)+1)\n",
      "    vals = [[] for i in range(len(keys))]\n",
      "    partitions = dict(zip(keys, vals))\n",
      "    which_bin = np.digitize(vector, bins)\n",
      "    for i in range(len(which_bin)):\n",
      "        partitions[which_bin[i]].append(i)\n",
      "    return partitions.values()\n",
      "\n",
      "\n",
      "def find_which_partition(element, partitioned_vector):\n",
      "    \"\"\" Returns the partition an element is in. E.g.\n",
      "        find_which_partition(v1, v) would return [v1,v2,v3]\n",
      "        if vector were partitioned as described in the doc\n",
      "        string for the partition function.\n",
      "    \"\"\"\n",
      "    for partition in partitioned_vector:\n",
      "        if element in partition:\n",
      "            return partition\n",
      "        \n",
      "        \n",
      "def make_groups(left_eigenvectors, num_intervals, num_eigenvectors):\n",
      "    \"\"\" Makes group as defined in coarse graining procedure. Vector\n",
      "        components v1,v2 are grouped together if x_n < v1,v2 < x_n+1, \n",
      "        for EACH of the first 'num_eigenvectors' eigenvectors specified.\n",
      "        The subinterval (x_n, x_n+1) are defined by [max(eigenvalue) - \n",
      "        min(eigenvalue)] / num_intervals.\n",
      "\n",
      "        Typically we take the first few non trivial eigenvectors to preserve\n",
      "        the long term behaviour of the RW; i.e. take <u1|, <u2|, <u3|.\n",
      "        \n",
      "        Roughly speaking, groups <u^alpha_i | and <u^alpha_j | together\n",
      "        if they are roughly equal to each other, for each alpha.\n",
      "\n",
      "    \"\"\"\n",
      "    \n",
      "    groups = []\n",
      "    partitioned_vectors = [partition(left_eigenvectors[i], num_intervals) for i in range(num_eigenvectors)]  #take first NON-TRIVIAL eigenvectors\n",
      "\n",
      "    #Add non-empty groups\n",
      "    for p0_i in partitioned_vectors[0]:\n",
      "        for element_p0_i in p0_i:\n",
      "            sets = []\n",
      "            sets.append(set(p0_i))\n",
      "            for partitioned_vector in partitioned_vectors[1:]:                            #exclude first vector\n",
      "                sets.append(set(find_which_partition(element_p0_i, partitioned_vector)))\n",
      "            intersections = list(set.intersection(*sets))\n",
      "            if len(intersections) > 1:\n",
      "                if intersections not in groups:\n",
      "                    groups.append(intersections)\n",
      "                \n",
      "    #Add elements not in groups            \n",
      "    flattened_groups = set([item for sublist in groups for item in sublist])\n",
      "    all_vector_components = set(range(len(left_eigenvectors[0])))\n",
      "    for component in all_vector_components - flattened_groups:\n",
      "        groups.append(component)\n",
      "        \n",
      "    return groups\n",
      "\n",
      "#Get rid of this?\n",
      "def find_similar_nodes(W, tolerance):\n",
      "    groups = []\n",
      "    for i in range(W.shape[0]):\n",
      "        temp = [i]\n",
      "        if not i in [item for sublist in groups for item in sublist]:  #flattened groups\n",
      "            for j in range(i+1,W.shape[0]):\n",
      "                if all(abs(W[:,i] - W[:,j]) < tolerance):\n",
      "                    temp.append(j)\n",
      "            groups.append(temp)\n",
      "    return groups\n",
      "\n",
      "\n",
      "def node_degree(node, A):\n",
      "    return sum(A[:,node])\n",
      "\n",
      "\n",
      "def degree_of_group(group_number, groups, A):\n",
      "    if type(groups[group_number]) == list:\n",
      "        return sum([node_degree(node, A) for node in groups[group_number]])\n",
      "    else:\n",
      "        return node_degree(groups[group_number], A)\n",
      "\n",
      "\n",
      "def make_K(groups, A):\n",
      "    K = np.zeros((A.shape[0], len(groups)))\n",
      "    for node in range(A.shape[0]):\n",
      "        for group_number in range(len(groups)):\n",
      "            if type(groups[group_number]) == list:\n",
      "                if node in groups[group_number]:     #if node in group\n",
      "                    K[node, group_number] = float(node_degree(node, A)) / degree_of_group(group_number, groups, A)\n",
      "            else:\n",
      "                if node == groups[group_number]:\n",
      "                    K[node, group_number] = float(node_degree(node, A)) / degree_of_group(group_number, groups, A)\n",
      "    return np.matrix(K)\n",
      "\n",
      "\n",
      "\n",
      "def make_R(groups, A):\n",
      "    R = np.zeros((len(groups), A.shape[0]))\n",
      "    for group_number in range(len(groups)):\n",
      "        for node in range(A.shape[0]):\n",
      "            if type(groups[group_number]) == list:     #group contains lists and int's, e.g. [[1,2,3], 4]\n",
      "                if node in groups[group_number]:\n",
      "                    R[group_number, node] = 1\n",
      "            else:\n",
      "                if node == groups[group_number]:\n",
      "                    R[group_number, node] = 1\n",
      "    return R\n",
      "\n",
      "\n",
      "\n",
      "def coarse_grain_W(num_intervals, num_eigenvectors, A):\n",
      "    W = A / np.sum(A, 0)    #stochastic matrix\n",
      "    left_eigenvectors = eig(W, left = True, right = False)[1]\n",
      "    groups = make_groups(left_eigenvectors, num_intervals , num_eigenvectors)\n",
      "    R = make_R(groups, A)\n",
      "    K = make_K(groups, A)\n",
      "    return np.dot(R, np.dot(W, K))\n",
      "\n",
      "\n",
      "\n",
      "def inspect_coarse_graining(num_intervals, num_eigenvectors, A):\n",
      "    \"\"\" Prints some quantitative comparisons between the \n",
      "        coarse grained and non - coarse grained graphs.\n",
      "    \"\"\"\n",
      "    \n",
      "    W_tilde = coarse_grain_W(num_intervals, num_eigenvectors, A)\n",
      "    W = A / np.sum(A, 0)\n",
      "    print 'Dimension [After, Before]: ' + str([W_tilde.shape[0], W.shape[0]])\n",
      "    l_tilde,l = eig(W_tilde)[0], eig(W)[0]\n",
      "    print 'Difference in eigenvalues: ' + str(abs((l_tilde - l[:len(l_tilde)])[:num_eigenvectors]))\n",
      "    plt.figure()\n",
      "    plt.xlabel('Alpha')\n",
      "    plt.ylabel('Eigenvalue')\n",
      "    plt.title('For ' + str(num_intervals) + ' intervals')\n",
      "    plt.plot(l_tilde[:num_eigenvectors+8], 'ko')\n",
      "    plt.plot(l[:num_eigenvectors+8], 'ro')\n",
      "\n",
      "     \n",
      "import networkx as nx\n",
      "import CoarseGrainLibrary as lib\n",
      "import numpy as np\n",
      "from scipy.linalg import eig\n",
      "if __name__ == '__main__':\n",
      "        function()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'profile' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-8-a7d15b67f2a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Profiling Spectral Coarse Graining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mg_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_gnp_random_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madjacency_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'profile' is not defined"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"\n",
      "#Profiling find_analytic_MFPT\n",
      "@profile\n",
      "def function():\n",
      "    g_trial = nx.fast_gnp_random_graph(10000, 0.05)\n",
      "    A = nx.adjacency_matrix(g_trial)\n",
      "    tolerance = 0.5\n",
      "    max_iteration = 3\n",
      "    N = float(np.sum(A))                                 #used in finding stationary probabilities\n",
      "    max_error = 2*tolerance\n",
      "    counter = 0\n",
      "    row = A.shape[0]\n",
      "    prob_matrix = np.matrix(np.identity(row))            #P(t = 0)_ij = Delta_ij \n",
      "    stationary_prob = np.array(np.sum(A,0)[0] / float(np.sum(A)))[0]\n",
      "    zeroth_moment_matrix = np.matrix(np.vstack(tuple([-stationary_prob for i in xrange(len(stationary_prob))])).T)  # - p_j^inf\n",
      "    del stationary_prob\n",
      "    \n",
      "    while max_error > tolerance and counter < max_iteration:\n",
      "        counter += 1\n",
      "        max_error = 0\n",
      "        err_check = 0.0\n",
      "        zeroth_moment_matrix += prob_matrix\n",
      "        \n",
      "        for j in xrange(row):\n",
      "            err_check = max(prob_matrix[:,j] - lib.find_stationary_probability(j, N, g_trial))\n",
      "            if err_check > max_error:\n",
      "                max_error = err_check\n",
      "            \n",
      "        prob_matrix = lib.find_probability_matrix_recursively(A, g_trial, prob_matrix)\n",
      "    \n",
      "    MFPT_matrix = zeroth_moment_matrix                                  \n",
      "    MFPT_matrix = np.multiply( np.diag(MFPT_matrix) - MFPT_matrix, zip(np.array(float(np.sum(A)) / np.sum(A,0)[0] )[0]))  # T_ij = (R_jj - R_ij) / p_j^inf\n",
      "    np.fill_diagonal(MFPT_matrix, float(np.sum(A)) / np.sum(A,0)[0] )  \n",
      "    return MFPT_matrix\n",
      "\n",
      "\n",
      "import networkx as nx\n",
      "import CoarseGrainLibrary as lib\n",
      "import numpy as np\n",
      "if __name__ == '__main__':\n",
      "        function()\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}